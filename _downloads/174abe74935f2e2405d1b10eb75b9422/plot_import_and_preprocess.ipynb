{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nImport and Pre-process Data\n===========================\n\nThis example shows how to import Data and do a basic preprocess pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from BirdSongToolbox.import_data import ImportData\nfrom BirdSongToolbox.preprocess import multi_bpf, hilbert_module, common_average_reference_array\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\nimport inspect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Basic Workflow\n--------------\n\nWhen using BirdSongToolbox you will need to have data in which you want to work on\n\nAlthough not required, it is convenient to use the Import Classes to import properly formated\nderived data this way you can guarantee that you have all of the data and meta data needed and\nthat it is all synchronized with each other\n\nAs this example assumes that you have not yet configured BirdSongToolbox to automatically know\nwhere to look for data we will go through the optional step of telling the toolbox where we\nwould like it to impor from. In this case we will import data used for testing the package.\n(Don't worry about this if you are unfamiliar with pytest)\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select bird_id and session\nbird_id = 'z007'\nsession = 'day-2016-09-09'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "src_file_path = inspect.getfile(lambda: None)\nproject_dir = Path(src_file_path).resolve().parents[1]\nprint(project_dir)\ndata_dir = project_dir / \"BirdSongToolbox\" / \"data\" / \"Chunk_Data_Demo\"\n\n# Import Data\nzdata = ImportData(bird_id=bird_id, session=session, location=data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The neural and audio data files BirdSongToolbox works with are almost alway numpy ndarrays with\ntheir last dimension being samples. This allows for versitility in functionality and computational\nsimplicity. However, to Demonstrate the most basic api functionality we are going to select a\nsingle chunk to preprocess.\n\n*Note:* This is not always necessary, as their are wrapper functions that can work the most common\nversions of various preprocessed data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "neural_data = zdata.song_neural[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Common Average Reference\n------------------------\n\nTypically it is useful to rereference neural data to remove noise or motion artifacts. For the test\ndata it is convenient to use a Common Average Reference (CAR). Basically you subtract the mean of all\nof your neural channels from each channels. The logic here is that most of what is commone accross all\nof your channels would be dominated by noise and this would improve the Signal to Noise ratio.\n\nWhen doing a CAR it is best to exclude channels that are known to be noisy or unrealiable to prevent\nintroducing noise into your other channels. So we are going to declare which channels to exclude from\nthe CAR.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Common Average Reference\nbad_channels = [24, 28]  # Define Bad Channels\ncar_data = common_average_reference_array(neural_data=neural_data, bad_channels=bad_channels)  # CAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Band Pass Filter\n----------------\n\nNext we can bandpass filter the data to get out frequencies that we want. Depending on your own preference\nthis filtering will be done using either neurodsp or mne (optional dependency). For this example we will\nbe using mne.\n\nWhen using the multi_bpf function you can make as many band pass filters as you want. Each filtered data\nndarray will be returned in a list\n\nNo matter your preferred backend you can print out detailed reports on the filters used using the verbose\nparameter\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fs = 1000  # Neural Data is sampled at 1 kHz\nl_freqs = [10, 100]  # The lower bound of the band pass filters\nh_freqs = [20, 200]  # The Upper bound of the band pass filter\n\nfiltered_data = multi_bpf(chunk_neural_data=car_data, fs=fs, l_freqs=l_freqs, h_freqs=h_freqs,\n                          verbose=True)\nfiltered_data = np.asarray(filtered_data)  # Make a view as a ndarray"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}